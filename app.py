from flask import Flask, request, jsonify
import re
import pickle
import pandas as pd
import numpy as np
import logging

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ñ€Ð¸ ÑÑ‚Ð°Ñ€Ñ‚Ðµ ÑÐµÑ€Ð²ÐµÑ€Ð°
try:
    with open('xgboost_token_model.pkl', 'rb') as f:
        model_artifacts = pickle.load(f)
    print("âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!")
except Exception as e:
    print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}")
    model_artifacts = None

def parse_token_data(text):
    """
    ÐŸÐ°Ñ€ÑÐ¸Ñ‚ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ‚Ð¾ÐºÐµÐ½Ð° Ð² ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
    """
    try:
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ñ‚Ð¾ÐºÐµÐ½Ð°
        token_data = {}
        
        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ðµ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸
        
        # Market Cap
        mcap_match = re.search(r'MCap:\s*\$?([0-9.]+)([KMB]?)', text, re.IGNORECASE)
        if mcap_match:
            value = float(mcap_match.group(1))
            unit = mcap_match.group(2).upper()
            if unit == 'K':
                value *= 1000
            elif unit == 'M':
                value *= 1000000
            elif unit == 'B':
                value *= 1000000000
            token_data['market_cap'] = value
        else:
            token_data['market_cap'] = 0
        
        # Liquidity
        liq_match = re.search(r'Liq:\s*\$?([0-9.]+)([KMB]?)', text, re.IGNORECASE)
        if liq_match:
            value = float(liq_match.group(1))
            unit = liq_match.group(2).upper()
            if unit == 'K':
                value *= 1000
            elif unit == 'M':
                value *= 1000000
            elif unit == 'B':
                value *= 1000000000
            token_data['liquidity'] = value
        else:
            token_data['liquidity'] = 0
        
        # Volume
        vol_match = re.search(r'Volume\s+\d+min:\s*\$?([0-9.]+)([KMB]?)', text, re.IGNORECASE)
        if vol_match:
            value = float(vol_match.group(1))
            unit = vol_match.group(2).upper()
            if unit == 'K':
                value *= 1000
            elif unit == 'M':
                value *= 1000000
            elif unit == 'B':
                value *= 1000000000
            token_data['volume_1min'] = value
        else:
            token_data['volume_1min'] = 0
        
        # Last Volume
        last_vol_match = re.search(r'Last Volume:\s*\$?([0-9.]+)([KMB]?)\s+([0-9.]+)x', text, re.IGNORECASE)
        if last_vol_match:
            value = float(last_vol_match.group(1))
            unit = last_vol_match.group(2).upper()
            multiplier = float(last_vol_match.group(3))
            
            if unit == 'K':
                value *= 1000
            elif unit == 'M':
                value *= 1000000
            elif unit == 'B':
                value *= 1000000000
                
            token_data['last_volume'] = value
            token_data['last_volume_multiplier'] = multiplier
        else:
            token_data['last_volume'] = 0
            token_data['last_volume_multiplier'] = 1
        
        # Token Age (ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹)
        age_match = re.search(r'Token Age:\s*(?:(\d+)h\s*)?(?:(\d+)m\s*)?(?:(\d+)s\s*)?', text, re.IGNORECASE)
        if age_match:
            hours = int(age_match.group(1)) if age_match.group(1) else 0
            minutes = int(age_match.group(2)) if age_match.group(2) else 0
            seconds = int(age_match.group(3)) if age_match.group(3) else 0
            total_minutes = hours * 60 + minutes + seconds / 60
            token_data['token_age_numeric'] = total_minutes
        else:
            token_data['token_age_numeric'] = 0
        
        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð´ÐµÑ€Ð¶Ð°Ñ‚ÐµÐ»ÐµÐ¹ Ð¿Ð¾ Ñ†Ð²ÐµÑ‚Ð°Ð¼
        holders_match = re.search(r'ðŸŸ¢:\s*(\d+)\s*\|\s*ðŸ”µ:\s*(\d+)\s*\|\s*ðŸŸ¡:\s*(\d+)\s*\|\s*â­•ï¸:\s*(\d+)', text)
        if holders_match:
            token_data['green_holders'] = int(holders_match.group(1))
            token_data['blue_holders'] = int(holders_match.group(2))
            token_data['yellow_holders'] = int(holders_match.group(3))
            token_data['circle_holders'] = int(holders_match.group(4))
        else:
            token_data['green_holders'] = 0
            token_data['blue_holders'] = 0
            token_data['yellow_holders'] = 0
            token_data['circle_holders'] = 0
        
        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð´ÐµÑ€Ð¶Ð°Ñ‚ÐµÐ»ÐµÐ¹
        special_holders_match = re.search(r'ðŸ¤¡:\s*(\d+)\s*\|\s*ðŸŒž:\s*(\d+)\s*\|\s*ðŸŒ—:\s*(\d+)\s*\|\s*ðŸŒš:\s*(\d+)', text)
        if special_holders_match:
            token_data['clown_holders'] = int(special_holders_match.group(1))
            token_data['sun_holders'] = int(special_holders_match.group(2))
            token_data['half_moon_holders'] = int(special_holders_match.group(3))
            token_data['dark_moon_holders'] = int(special_holders_match.group(4))
        else:
            token_data['clown_holders'] = 0
            token_data['sun_holders'] = 0
            token_data['half_moon_holders'] = 0
            token_data['dark_moon_holders'] = 0
        
        # Total holders
        total_holders_match = re.search(r'Total:\s*(\d+)', text)
        if total_holders_match:
            token_data['total_holders'] = int(total_holders_match.group(1))
        else:
            # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÐºÐ°Ðº ÑÑƒÐ¼Ð¼Ñƒ Ð²ÑÐµÑ… Ñ‚Ð¸Ð¿Ð¾Ð² Ð´ÐµÑ€Ð¶Ð°Ñ‚ÐµÐ»ÐµÐ¹
            token_data['total_holders'] = (
                token_data['green_holders'] + token_data['blue_holders'] + 
                token_data['yellow_holders'] + token_data['circle_holders']
            )
        
        # Top 10 percent
        top10_match = re.search(r'Top10:\s*([0-9.]+)%', text)
        if top10_match:
            token_data['top10_percent'] = float(top10_match.group(1))
        else:
            token_data['top10_percent'] = 50.0  # default
        
        # Total percent Ð¸ Total now percent
        total_match = re.search(r'Total:\s*([0-9.]+)%', text)
        if total_match:
            token_data['total_percent'] = float(total_match.group(1))
        else:
            token_data['total_percent'] = 100.0
        
        total_now_match = re.search(r'Total now:\s*([0-9.]+)%', text)
        if total_now_match:
            token_data['total_now_percent'] = float(total_now_match.group(1))
        else:
            token_data['total_now_percent'] = 100.0
        
        # Insiders
        insiders_match = re.search(r'Insiders:\s*(\d+)\s+hold\s+([0-9.]+)%', text)
        if insiders_match:
            token_data['insiders_count'] = int(insiders_match.group(1))
            token_data['insiders_percent'] = float(insiders_match.group(2))
        else:
            token_data['insiders_count'] = 0
            token_data['insiders_percent'] = 0.0
        
        # Snipers
        snipers_match = re.search(r'Snipers:\s*(\d+)', text)
        if snipers_match:
            token_data['snipers_count'] = int(snipers_match.group(1))
        else:
            token_data['snipers_count'] = 0
        
        # Bundle
        bundle_total_match = re.search(r'Bundle:.*?Total:\s*(\d+)', text, re.DOTALL)
        if bundle_total_match:
            token_data['bundle_total'] = int(bundle_total_match.group(1))
        else:
            token_data['bundle_total'] = 0
        
        bundle_supply_match = re.search(r'Supply:\s*([0-9.]+)%', text)
        if bundle_supply_match:
            token_data['bundle_supply_percent'] = float(bundle_supply_match.group(1))
        else:
            token_data['bundle_supply_percent'] = 0.0
        
        # Dev holds
        dev_holds_match = re.search(r'Dev holds\s+([0-9.]+)%', text)
        if dev_holds_match:
            token_data['dev_holds_percent'] = float(dev_holds_match.group(1))
        else:
            token_data['dev_holds_percent'] = 0.0
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ (ÐºÐ°Ðº Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸)
        token_data['volume_to_liquidity'] = float(
            np.log1p(token_data['volume_1min']) / np.log1p(token_data['liquidity'] + 1)
            if token_data['liquidity'] > 0 else 0
        )
        
        # Ð›Ð¾Ð³Ð°Ñ€Ð¸Ñ„Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸
        token_data['log_market_cap'] = float(np.log1p(token_data['market_cap']))
        token_data['log_liquidity'] = float(np.log1p(token_data['liquidity']))
        token_data['log_volume_1min'] = float(np.log1p(token_data['volume_1min']))
        token_data['log_last_volume'] = float(np.log1p(token_data['last_volume']))
        
        # ÐšÐ¾Ð½Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ñ†Ð¸Ñ Ð´ÐµÑ€Ð¶Ð°Ñ‚ÐµÐ»ÐµÐ¹
        token_data['holder_concentration'] = int(
            token_data['green_holders'] + token_data['blue_holders'] + 
            token_data['yellow_holders'] + token_data['circle_holders']
        )
        
        # Ð Ð¸ÑÐº-Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ñ‹
        token_data['total_risk_percent'] = float(
            token_data['dev_holds_percent'] + token_data['insiders_percent']
        )
        
        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð² JSON-ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹
        return convert_to_json_serializable(token_data)
        
    except Exception as e:
        logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°: {e}")
        return {}

def convert_to_json_serializable(obj):
    """ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ numpy Ñ‚Ð¸Ð¿Ñ‹ Ð² ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ðµ Python Ñ‚Ð¸Ð¿Ñ‹ Ð´Ð»Ñ JSON"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_to_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_json_serializable(item) for item in obj]
    else:
        return obj

def predict_token_success(token_data):
    """
    ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚ÑŒ Ñ‚Ð¾ÐºÐµÐ½Ð°
    """
    if model_artifacts is None:
        return {'error': 'ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°'}
    
    try:
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ DataFrame
        df_new = pd.DataFrame([token_data])
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°ÑŽÑ‰Ð¸Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹
        for col in model_artifacts['feature_names']:
            if col not in df_new.columns:
                df_new[col] = 0
        
        # Ð‘ÐµÑ€ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½ÑƒÐ¶Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð² Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ
        df_new = df_new[model_artifacts['feature_names']]
        
        # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ð¸Ð¼Ð¿ÑƒÑ‚ÐµÑ€
        df_imputed = pd.DataFrame(
            model_artifacts['imputer'].transform(df_new), 
            columns=model_artifacts['feature_names']
        )
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
        prediction = int(model_artifacts['model'].predict(df_imputed)[0])
        probability = float(model_artifacts['model'].predict_proba(df_imputed)[0, 1])
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸
        confidence_score = abs(probability - 0.5) * 2
        if confidence_score > 0.8:
            confidence_level = "ÐžÑ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ"
        elif confidence_score > 0.6:
            confidence_level = "Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ"
        elif confidence_score > 0.4:
            confidence_level = "Ð¡Ñ€ÐµÐ´Ð½ÑÑ"
        else:
            confidence_level = "ÐÐ¸Ð·ÐºÐ°Ñ"
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑŽ
        if probability >= 0.7:
            recommendation = "ÐŸÐžÐšÐ£ÐŸÐÐ¢Ð¬"
            risk_level = "ÐÐ¸Ð·ÐºÐ¸Ð¹"
        elif probability >= 0.5:
            recommendation = "Ð˜Ð—Ð£Ð§Ð˜Ð¢Ð¬"
            risk_level = "Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹"
        else:
            recommendation = "ÐŸÐ ÐžÐŸÐ£Ð¡Ð¢Ð˜Ð¢Ð¬"
            risk_level = "Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹"
        
        result = {
            'prediction': 'Ð”Ð' if prediction == 1 else 'ÐÐ•Ð¢',
            'probability': round(float(probability), 4),
            'probability_percent': f"{probability*100:.1f}%",
            'confidence_level': confidence_level,
            'confidence_score': round(float(confidence_score), 4),
            'recommendation': recommendation,
            'risk_level': risk_level,
            'threshold_conservative': 'Ð”Ð' if probability >= 0.7 else 'ÐÐ•Ð¢',
            'threshold_optimal': 'Ð”Ð' if probability >= 0.5 else 'ÐÐ•Ð¢',
            'threshold_aggressive': 'Ð”Ð' if probability >= 0.3 else 'ÐÐ•Ð¢'
        }
        
        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ Ð² JSON-ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹
        return convert_to_json_serializable(result)
        
    except Exception as e:
        logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ: {e}")
        return {'error': f'ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ: {str(e)}'}

@app.route('/health', methods=['GET'])
def health_check():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ€Ð°Ð±Ð¾Ñ‚Ð¾ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸ API"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_artifacts is not None,
        'version': '1.0'
    })

@app.route('/predict', methods=['POST'])
def predict():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ ÑÐ½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ"""
    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({'error': 'ÐÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‚ÑŒ Ð¿Ð¾Ð»Ðµ "text" Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ñ‚Ð¾ÐºÐµÐ½Ð°'}), 400
        
        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ñ‚ÐµÐºÑÑ‚
        token_data = parse_token_data(data['text'])
        
        if not token_data:
            return jsonify({'error': 'ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð°Ñ€ÑÐ¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ‚Ð¾ÐºÐµÐ½Ð°'}), 400
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
        result = predict_token_success(token_data)
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ€Ð°ÑÐ¿Ð°Ñ€ÑÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ¸
        if data.get('include_parsed_data', False):
            result['parsed_data'] = convert_to_json_serializable(token_data)
        
        return jsonify(result)
        
    except Exception as e:
        logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° API: {e}")
        return jsonify({'error': f'Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÑÑ Ð¾ÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð°: {str(e)}'}), 500

@app.route('/test', methods=['GET'])
def test():
    """Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÑÐ½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚ Ñ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    test_text = """ðŸ€ Maybe Scalp it? âœ¯âœ¯âœ¯âœ¯âœ¯

ðŸŽ² $lazycoin | does nothing

8erVzAoR4yD22fmQYB1kUGn9uLQuDaLZjd85wnhWbonk | ð•s
â”” Launchpad: LetsBonk.fun

â³Token Age: 58m 32s
 â”œ MCap: $88K
 â”” Liq: $40K
 â”” Volume 5min: $73k ðŸŸ¡
 â”” Last Volume: $4k 14.9x ðŸŸ£
> First 70 holders:


ðŸŒšðŸŒšðŸŒšðŸŒšðŸŒšâ­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸
â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸
â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸
â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸ðŸŸ¢â­•ï¸â­•ï¸â­•ï¸
â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸
ðŸŸ¡ðŸŸ¡â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸ðŸ”µðŸŸ¡
â­•ï¸â­•ï¸â­•ï¸â­•ï¸ðŸŸ¡â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸

â”œ ðŸŸ¢: 1 | ðŸ”µ: 1 | ðŸŸ¡: 4 | â­•ï¸: 59
â”œ ðŸ¤¡: 0 | ðŸŒž: 0 | ðŸŒ—: 0 | ðŸŒš: 5
â”œ Total: 87.5%
â”” Total now: 1.1%
> Holders:
 â”œ Top10: 23.7% ðŸŸ¢| Total: 406
 â”œ Insiders: 0 hold 0% ðŸŸ¢
 â”” Snipers: 5
> Bundle:
 â”œ Total: 0
 â”” Supply: 0% ðŸŸ¢
> Dev:
 â”œ Migrations: 2/319 (0.6%)
 â”” Dev holds 0% ðŸŸ¢"""
    
    token_data = parse_token_data(test_text)
    result = predict_token_success(token_data)
    result['parsed_data'] = convert_to_json_serializable(token_data)
    
    return jsonify(result)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))  # Railway Ð¿ÐµÑ€ÐµÐ´Ð°ÐµÑ‚ Ð¿Ð¾Ñ€Ñ‚ Ñ‡ÐµÑ€ÐµÐ· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ
    app.run(host='0.0.0.0', port=port, debug=False)